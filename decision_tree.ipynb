{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import env\n",
    "import os\n",
    "import acquire\n",
    "import prepare\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pydataset import data\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import accuracy_score,\\\n",
    "precision_score,\\\n",
    "recall_score,\\\n",
    "classification_report,\\\n",
    "confusion_matrix\n",
    "from sklearn.tree import\\\n",
    "DecisionTreeClassifier as dt,\\\n",
    "plot_tree,\\\n",
    "export_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the titanic data, in your classification-exercises repository, create a notebook, <i>decision_tree.ipynb</i> where you will do the following:\n",
    "\n",
    "1. What is your baseline prediction? What is your baseline accuracy? remember: your baseline prediction for a classification problem is predicting the most prevelant class in the training dataset (the mode). When you make those predictions, what is your accuracy? This is your baseline accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Fit the decision tree classifier to your training sample and transform (i.e. make predictions on the training sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Evaluate your in-sample results using the model score, confusion matrix, and classification report."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Compute: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Run through steps 2-4 using a different max_depth value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Which model performs better on your in-sample data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Which model performs best on your out-of-sample data, the validate set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic = acquire.get_titanic_data('titanic_db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'acquire' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m prepare\u001b[39m.\u001b[39;49mprep_titanic()\n",
      "File \u001b[0;32m~/codeup-data-science/classification-exercises/prepare.py:27\u001b[0m, in \u001b[0;36mprep_titanic\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mprep_titanic\u001b[39m():\n\u001b[1;32m     23\u001b[0m \u001b[39m    \u001b[39m\u001b[39m'''\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[39m    Pulls data from mySql db and assigns as titanic.\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[39m    This function will drop duplicate columns and encode the rest of the categorical columns.\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[39m    '''\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m     titanic \u001b[39m=\u001b[39m acquire\u001b[39m.\u001b[39mget_titanic_data(\u001b[39m'\u001b[39m\u001b[39mtitanic_db\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     28\u001b[0m     titanic \u001b[39m=\u001b[39m titanic\u001b[39m.\u001b[39mdrop(columns\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mclass\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39membark_town\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mdeck\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m     29\u001b[0m     dummy_sex \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mget_dummies(titanic[\u001b[39m'\u001b[39m\u001b[39msex\u001b[39m\u001b[39m'\u001b[39m], drop_first\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\u001b[39m.\u001b[39mastype(\u001b[39mint\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'acquire' is not defined"
     ]
    }
   ],
   "source": [
    "prepare.prep_titanic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "codeup",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
