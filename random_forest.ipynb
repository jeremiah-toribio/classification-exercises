{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lots of Imports for tools that would normally be used in a project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# My created .py files for modularization\n",
    "import env\n",
    "import os\n",
    "import acquire\n",
    "import prepare\n",
    "# Array and Dataframes\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# Load datasets\n",
    "from pydataset import data\n",
    "# Evaluation: Visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "# Evaluation: Statistical Analysis\n",
    "from scipy import stats\n",
    "# Modeling\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import accuracy_score,\\\n",
    "precision_score,\\\n",
    "recall_score,\\\n",
    "classification_report,\\\n",
    "confusion_matrix\n",
    "from sklearn.ensemble import\\\n",
    "RandomForestClassifier as rf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions\n",
    "#### Create a new notebook, random_forests, and work with titanic data to do the following:\n",
    "\n",
    "> Fit the Random Forest classifier to your training sample and transform (i.e. make predictions on the training sample) setting the random_state accordingly and setting min_samples_leaf = 1 and max_depth = 10.\n",
    "\n",
    "Evaluate your results using the model score, confusion matrix, and classification report. \n",
    "### A: [Model Score](#model-score), [Confusion Matrix](#confusion-matrix), [Classification Report](#classification-report)\n",
    "\n",
    "Print and clearly label the following: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support.\n",
    "### A: [Accuracy, True Positive rate, False Positive rate, True Negative rate, False Negative rate, Precision, Recall, F1-Score, and Support](#a-accuracy-true-positive-rate-false-positive-rate-true-negative-rate-false-negative-rate-precision-recall-f1-score-and-support)\n",
    "\n",
    "Run through steps increasing your min_samples_leaf and decreasing your max_depth.\n",
    "### A: [Increase Min Leaf, Decrease max Depth](#increase-min-leaf-decrease-max-depth)\n",
    "\n",
    "What are the differences in the evaluation metrics? Which performs better on your in-sample data? Why?\n",
    "### A: [Comparing Model 1 Train and Validate Reports](#comparing-model-1-train-and-validate-reports)</br>The validation set does significantly worst than the training set in predicting those that will survive. - there is a pretty consistent base of metrics that will fluctuate. \n",
    "After making a few models, which one has the best performance (or closest metrics) on both train and validate?\n",
    "### A: [Min Samples Leaves 1-5 , 1-20 Mad Depth](#min-samples-leaf-1-5)</br>With a min sample leaf size of 3 there is a consistent accuracy score with 1-20 max depth of about 90%. Although suboptimal it is very close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# acquiring and preparing data\n",
    "# prep_titanic has acquire built in\n",
    "titanic = prepare.prep_titanic()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, validate, test  = prepare.splitter(titanic,target='survived')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "survived\n",
       "0    307\n",
       "1    191\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# determining baseline\n",
    "train['survived'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determining Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6164658634538153"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finding baseline accuracy to compare to predictions\n",
    "train['label'] = ['survived'] == '0'\n",
    "baseline_accuracy = (train.survived == 0).mean()\n",
    "baseline_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1 Defined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model 1\n",
    "x_train = train.drop(columns=['survived','label','sex','embarked'])\n",
    "y_train = train[['survived']]\n",
    "y_train = y_train.values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting parameters for decision tree\n",
    "rf1 = rf(max_depth=10,min_samples_leaf=1,random_state=4343)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit and Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_depth=10, random_state=4343)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=10, random_state=4343)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(max_depth=10, random_state=4343)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf1.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_predictions = rf1.predict(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9718875502008032"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf1.score(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred survived</th>\n",
       "      <th>pred opposite</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>actual opposite</th>\n",
       "      <td>307</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual survived</th>\n",
       "      <td>14</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 pred survived  pred opposite\n",
       "actual opposite            307              0\n",
       "actual survived             14            177"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "    confusion_matrix(y_train,model1_predictions),\n",
    "    columns = ['pred survived','pred opposite'], index=['actual opposite','actual survived']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.956386</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.977707</td>\n",
       "      <td>307.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.926702</td>\n",
       "      <td>0.961957</td>\n",
       "      <td>191.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.971888</td>\n",
       "      <td>0.971888</td>\n",
       "      <td>0.971888</td>\n",
       "      <td>0.971888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.978193</td>\n",
       "      <td>0.963351</td>\n",
       "      <td>0.969832</td>\n",
       "      <td>498.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.973114</td>\n",
       "      <td>0.971888</td>\n",
       "      <td>0.971666</td>\n",
       "      <td>498.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score     support\n",
       "0              0.956386  1.000000  0.977707  307.000000\n",
       "1              1.000000  0.926702  0.961957  191.000000\n",
       "accuracy       0.971888  0.971888  0.971888    0.971888\n",
       "macro avg      0.978193  0.963351  0.969832  498.000000\n",
       "weighted avg   0.973114  0.971888  0.971666  498.000000"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1_test_report = pd.DataFrame(classification_report(y_train,model1_predictions,output_dict=True)).T\n",
    "model1_test_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy, True Positive rate, False Positive rate, True Negative rate, False Negative rate, Precision, Recall, F1-Score, and Support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(307, 0, 14, 177)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compute_metrics(TN,FP,FN,TP):\n",
    "    all_ = (TP + TN + FP + FN)\n",
    "\n",
    "    accuracy = (TP + TN) / all_\n",
    "\n",
    "    TPR = recall = TP / (TP + FN)\n",
    "    FPR = FP / (FP + TN)\n",
    "\n",
    "    TNR = TN / (FP + TN)\n",
    "    FNR = FN / (FN + TP)\n",
    "\n",
    "    precision =  TP / (TP + FP)\n",
    "    f1 =  2 * ((precision * recall) / ( precision + recall))\n",
    "\n",
    "    support_pos = TP + FN\n",
    "    support_neg = FP + TN\n",
    "\n",
    "    print(f\"Accuracy: {accuracy}\\n\")\n",
    "    print(f\"True Positive Rate/Sensitivity/Recall/Power: {TPR}\")\n",
    "    print(f\"False Positive Rate/False Alarm Ratio/Fall-out: {FPR}\")\n",
    "    print(f\"True Negative Rate/Specificity/Selectivity: {TNR}\")\n",
    "    print(f\"False Negative Rate/Miss Rate: {FNR}\\n\")\n",
    "    print(f\"Precision/PPV: {precision}\")\n",
    "    print(f\"F1 Score: {f1}\\n\")\n",
    "    print(f\"Support (0): {support_pos}\")\n",
    "    print(f\"Support (1): {support_neg}\")\n",
    "confu = confusion_matrix(y_train,model1_predictions)\n",
    "TN, FP, FN, TP = confu.ravel()\n",
    "TN, FP, FN, TP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9718875502008032\n",
      "\n",
      "True Positive Rate/Sensitivity/Recall/Power: 0.9267015706806283\n",
      "False Positive Rate/False Alarm Ratio/Fall-out: 0.0\n",
      "True Negative Rate/Specificity/Selectivity: 1.0\n",
      "False Negative Rate/Miss Rate: 0.07329842931937172\n",
      "\n",
      "Precision/PPV: 1.0\n",
      "F1 Score: 0.9619565217391305\n",
      "\n",
      "Support (0): 191\n",
      "Support (1): 307\n"
     ]
    }
   ],
   "source": [
    "compute_metrics(TN, FP, FN, TP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1 Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_validate = validate.drop(columns=['survived','sex','embarked'])\n",
    "y_validate = validate[['survived']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_val = rf1.predict(x_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8037383177570093"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf1.score(x_validate,y_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred survived</th>\n",
       "      <th>pred opposite</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>actual opposite</th>\n",
       "      <td>116</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual survived</th>\n",
       "      <td>26</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 pred survived  pred opposite\n",
       "actual opposite            116             16\n",
       "actual survived             26             56"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "    confusion_matrix(y_validate,model1_val),\n",
    "    columns = ['pred survived','pred opposite'], index=['actual opposite','actual survived']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.816901</td>\n",
       "      <td>0.878788</td>\n",
       "      <td>0.846715</td>\n",
       "      <td>132.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.682927</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>82.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.803738</td>\n",
       "      <td>0.803738</td>\n",
       "      <td>0.803738</td>\n",
       "      <td>0.803738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.797340</td>\n",
       "      <td>0.780857</td>\n",
       "      <td>0.786994</td>\n",
       "      <td>214.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.801910</td>\n",
       "      <td>0.803738</td>\n",
       "      <td>0.800948</td>\n",
       "      <td>214.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score     support\n",
       "0              0.816901  0.878788  0.846715  132.000000\n",
       "1              0.777778  0.682927  0.727273   82.000000\n",
       "accuracy       0.803738  0.803738  0.803738    0.803738\n",
       "macro avg      0.797340  0.780857  0.786994  214.000000\n",
       "weighted avg   0.801910  0.803738  0.800948  214.000000"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1_val_report = pd.DataFrame(classification_report(y_validate,model1_val,output_dict=True)).T\n",
    "model1_val_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing Model 1 Train and Validate Reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score     support\n",
      "0              0.956386  1.000000  0.977707  307.000000\n",
      "1              1.000000  0.926702  0.961957  191.000000\n",
      "accuracy       0.971888  0.971888  0.971888    0.971888\n",
      "macro avg      0.978193  0.963351  0.969832  498.000000\n",
      "weighted avg   0.973114  0.971888  0.971666  498.000000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.816901</td>\n",
       "      <td>0.878788</td>\n",
       "      <td>0.846715</td>\n",
       "      <td>132.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.682927</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>82.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.803738</td>\n",
       "      <td>0.803738</td>\n",
       "      <td>0.803738</td>\n",
       "      <td>0.803738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.797340</td>\n",
       "      <td>0.780857</td>\n",
       "      <td>0.786994</td>\n",
       "      <td>214.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.801910</td>\n",
       "      <td>0.803738</td>\n",
       "      <td>0.800948</td>\n",
       "      <td>214.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score     support\n",
       "0              0.816901  0.878788  0.846715  132.000000\n",
       "1              0.777778  0.682927  0.727273   82.000000\n",
       "accuracy       0.803738  0.803738  0.803738    0.803738\n",
       "macro avg      0.797340  0.780857  0.786994  214.000000\n",
       "weighted avg   0.801910  0.803738  0.800948  214.000000"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(model1_test_report)\n",
    "model1_val_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model 2\n",
    "x_train2 = train.drop(columns=['survived','label','sex','embarked'])\n",
    "y_train2 = train[['survived']]\n",
    "y_train2 = y_train2.values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_depth=8, min_samples_leaf=3, random_state=4343)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" checked><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=8, min_samples_leaf=3, random_state=4343)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(max_depth=8, min_samples_leaf=3, random_state=4343)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# setting parameters for decision tree\n",
    "rf2 = rf(max_depth=6,min_samples_leaf=4,random_state=4343)\n",
    "rf2.fit(x_train2,y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2_predictions = rf1.predict(x_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.956386</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.977707</td>\n",
       "      <td>307.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.926702</td>\n",
       "      <td>0.961957</td>\n",
       "      <td>191.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.971888</td>\n",
       "      <td>0.971888</td>\n",
       "      <td>0.971888</td>\n",
       "      <td>0.971888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.978193</td>\n",
       "      <td>0.963351</td>\n",
       "      <td>0.969832</td>\n",
       "      <td>498.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.973114</td>\n",
       "      <td>0.971888</td>\n",
       "      <td>0.971666</td>\n",
       "      <td>498.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score     support\n",
       "0              0.956386  1.000000  0.977707  307.000000\n",
       "1              1.000000  0.926702  0.961957  191.000000\n",
       "accuracy       0.971888  0.971888  0.971888    0.971888\n",
       "macro avg      0.978193  0.963351  0.969832  498.000000\n",
       "weighted avg   0.973114  0.971888  0.971666  498.000000"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(classification_report(y_train2,model2_predictions,output_dict=True)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_validate2 = validate.drop(columns=['survived','sex','embarked'])\n",
    "y_validate2 = validate['survived']\n",
    "y_validate2 = y_validate2.values.ravel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2_val = rf2.predict(x_validate2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.801370</td>\n",
       "      <td>0.886364</td>\n",
       "      <td>0.841727</td>\n",
       "      <td>132.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.779412</td>\n",
       "      <td>0.646341</td>\n",
       "      <td>0.706667</td>\n",
       "      <td>82.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.794393</td>\n",
       "      <td>0.794393</td>\n",
       "      <td>0.794393</td>\n",
       "      <td>0.794393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.790391</td>\n",
       "      <td>0.766353</td>\n",
       "      <td>0.774197</td>\n",
       "      <td>214.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.792956</td>\n",
       "      <td>0.794393</td>\n",
       "      <td>0.789975</td>\n",
       "      <td>214.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score     support\n",
       "0              0.801370  0.886364  0.841727  132.000000\n",
       "1              0.779412  0.646341  0.706667   82.000000\n",
       "accuracy       0.794393  0.794393  0.794393    0.794393\n",
       "macro avg      0.790391  0.766353  0.774197  214.000000\n",
       "weighted avg   0.792956  0.794393  0.789975  214.000000"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(classification_report(y_validate2,model2_val,output_dict=True)).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Increase Min Leaf, Decrease Max Depth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Min Samples Leaf 1-5 \n",
    "Checking for max_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for depth of  1, the accuracy is 0.8\n",
      "for depth of  2, the accuracy is 0.81\n",
      "for depth of  3, the accuracy is 0.84\n",
      "for depth of  4, the accuracy is 0.86\n",
      "for depth of  5, the accuracy is 0.88\n",
      "for depth of  6, the accuracy is 0.91\n",
      "for depth of  7, the accuracy is 0.94\n",
      "for depth of  8, the accuracy is 0.96\n",
      "for depth of  9, the accuracy is 0.97\n",
      "for depth of 10, the accuracy is 0.97\n",
      "for depth of 11, the accuracy is 0.98\n",
      "for depth of 12, the accuracy is 0.99\n",
      "for depth of 13, the accuracy is 0.99\n",
      "for depth of 14, the accuracy is 1.0\n",
      "for depth of 15, the accuracy is 1.0\n",
      "for depth of 16, the accuracy is 1.0\n",
      "for depth of 17, the accuracy is 1.0\n",
      "for depth of 18, the accuracy is 1.0\n",
      "for depth of 19, the accuracy is 1.0\n"
     ]
    }
   ],
   "source": [
    "# 1\n",
    "for x in range(1,20):\n",
    "        tree = rf(max_depth=x, random_state=4343,min_samples_leaf=1)\n",
    "        tree.fit(x_train, y_train)\n",
    "        acc = tree.score(x_train, y_train)\n",
    "        print(f'for depth of {x:2}, the accuracy is {round(acc,2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for depth of  1, the accuracy is 0.76\n",
      "for depth of  2, the accuracy is 0.79\n",
      "for depth of  3, the accuracy is 0.79\n",
      "for depth of  4, the accuracy is 0.81\n",
      "for depth of  5, the accuracy is 0.81\n",
      "for depth of  6, the accuracy is 0.8\n",
      "for depth of  7, the accuracy is 0.82\n",
      "for depth of  8, the accuracy is 0.81\n",
      "for depth of  9, the accuracy is 0.81\n",
      "for depth of 10, the accuracy is 0.8\n",
      "for depth of 11, the accuracy is 0.8\n",
      "for depth of 12, the accuracy is 0.8\n",
      "for depth of 13, the accuracy is 0.81\n",
      "for depth of 14, the accuracy is 0.81\n",
      "for depth of 15, the accuracy is 0.81\n",
      "for depth of 16, the accuracy is 0.81\n",
      "for depth of 17, the accuracy is 0.8\n",
      "for depth of 18, the accuracy is 0.8\n",
      "for depth of 19, the accuracy is 0.8\n"
     ]
    }
   ],
   "source": [
    "# 1\n",
    "for x in range(1,20):\n",
    "        tree = rf(max_depth=x, random_state=4343,min_samples_leaf=1)\n",
    "        tree.fit(x_train, y_train)\n",
    "        acc = tree.score(x_validate, y_validate)\n",
    "        print(f'for depth of {x:2}, the accuracy is {round(acc,2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for depth of  1, the accuracy is 0.8\n",
      "for depth of  2, the accuracy is 0.81\n",
      "for depth of  3, the accuracy is 0.84\n",
      "for depth of  4, the accuracy is 0.85\n",
      "for depth of  5, the accuracy is 0.87\n",
      "for depth of  6, the accuracy is 0.9\n",
      "for depth of  7, the accuracy is 0.91\n",
      "for depth of  8, the accuracy is 0.93\n",
      "for depth of  9, the accuracy is 0.93\n",
      "for depth of 10, the accuracy is 0.94\n",
      "for depth of 11, the accuracy is 0.94\n",
      "for depth of 12, the accuracy is 0.94\n",
      "for depth of 13, the accuracy is 0.93\n",
      "for depth of 14, the accuracy is 0.94\n",
      "for depth of 15, the accuracy is 0.94\n",
      "for depth of 16, the accuracy is 0.94\n",
      "for depth of 17, the accuracy is 0.94\n",
      "for depth of 18, the accuracy is 0.94\n",
      "for depth of 19, the accuracy is 0.94\n"
     ]
    }
   ],
   "source": [
    "# 2\n",
    "for x in range(1,20):\n",
    "        tree = rf(max_depth=x, random_state=4343,min_samples_leaf=2)\n",
    "        tree.fit(x_train, y_train)\n",
    "        acc = tree.score(x_train, y_train)\n",
    "        print(f'for depth of {x:2}, the accuracy is {round(acc,2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for depth of  1, the accuracy is 0.76\n",
      "for depth of  2, the accuracy is 0.79\n",
      "for depth of  3, the accuracy is 0.79\n",
      "for depth of  4, the accuracy is 0.8\n",
      "for depth of  5, the accuracy is 0.8\n",
      "for depth of  6, the accuracy is 0.8\n",
      "for depth of  7, the accuracy is 0.81\n",
      "for depth of  8, the accuracy is 0.79\n",
      "for depth of  9, the accuracy is 0.8\n",
      "for depth of 10, the accuracy is 0.79\n",
      "for depth of 11, the accuracy is 0.79\n",
      "for depth of 12, the accuracy is 0.79\n",
      "for depth of 13, the accuracy is 0.79\n",
      "for depth of 14, the accuracy is 0.79\n",
      "for depth of 15, the accuracy is 0.79\n",
      "for depth of 16, the accuracy is 0.79\n",
      "for depth of 17, the accuracy is 0.79\n",
      "for depth of 18, the accuracy is 0.79\n",
      "for depth of 19, the accuracy is 0.79\n"
     ]
    }
   ],
   "source": [
    "# 2 val\n",
    "for x in range(1,20):\n",
    "        tree = rf(max_depth=x, random_state=4343,min_samples_leaf=2)\n",
    "        tree.fit(x_train, y_train)\n",
    "        acc = tree.score(x_validate, y_validate)\n",
    "        print(f'for depth of {x:2}, the accuracy is {round(acc,2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for depth of  1, the accuracy is 0.8\n",
      "for depth of  2, the accuracy is 0.81\n",
      "for depth of  3, the accuracy is 0.84\n",
      "for depth of  4, the accuracy is 0.85\n",
      "for depth of  5, the accuracy is 0.86\n",
      "for depth of  6, the accuracy is 0.89\n",
      "for depth of  7, the accuracy is 0.9\n",
      "for depth of  8, the accuracy is 0.91\n",
      "for depth of  9, the accuracy is 0.92\n",
      "for depth of 10, the accuracy is 0.92\n",
      "for depth of 11, the accuracy is 0.92\n",
      "for depth of 12, the accuracy is 0.92\n",
      "for depth of 13, the accuracy is 0.92\n",
      "for depth of 14, the accuracy is 0.92\n",
      "for depth of 15, the accuracy is 0.92\n",
      "for depth of 16, the accuracy is 0.92\n",
      "for depth of 17, the accuracy is 0.92\n",
      "for depth of 18, the accuracy is 0.92\n",
      "for depth of 19, the accuracy is 0.92\n"
     ]
    }
   ],
   "source": [
    "# 3\n",
    "for x in range(1,20):\n",
    "        tree = rf(max_depth=x, random_state=4343,min_samples_leaf=3)\n",
    "        tree.fit(x_train, y_train)\n",
    "        acc = tree.score(x_train, y_train)\n",
    "        print(f'for depth of {x:2}, the accuracy is {round(acc,2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for depth of  1, the accuracy is 0.76\n",
      "for depth of  2, the accuracy is 0.79\n",
      "for depth of  3, the accuracy is 0.79\n",
      "for depth of  4, the accuracy is 0.8\n",
      "for depth of  5, the accuracy is 0.81\n",
      "for depth of  6, the accuracy is 0.81\n",
      "for depth of  7, the accuracy is 0.79\n",
      "for depth of  8, the accuracy is 0.79\n",
      "for depth of  9, the accuracy is 0.81\n",
      "for depth of 10, the accuracy is 0.81\n",
      "for depth of 11, the accuracy is 0.81\n",
      "for depth of 12, the accuracy is 0.82\n",
      "for depth of 13, the accuracy is 0.81\n",
      "for depth of 14, the accuracy is 0.81\n",
      "for depth of 15, the accuracy is 0.81\n",
      "for depth of 16, the accuracy is 0.81\n",
      "for depth of 17, the accuracy is 0.81\n",
      "for depth of 18, the accuracy is 0.81\n",
      "for depth of 19, the accuracy is 0.81\n"
     ]
    }
   ],
   "source": [
    "# 3 val\n",
    "for x in range(1,20):\n",
    "        tree = rf(max_depth=x, random_state=4343,min_samples_leaf=3)\n",
    "        tree.fit(x_train, y_train)\n",
    "        acc = tree.score(x_validate, y_validate)\n",
    "        print(f'for depth of {x:2}, the accuracy is {round(acc,2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for depth of  1, the accuracy is 0.8\n",
      "for depth of  2, the accuracy is 0.8\n",
      "for depth of  3, the accuracy is 0.84\n",
      "for depth of  4, the accuracy is 0.85\n",
      "for depth of  5, the accuracy is 0.87\n",
      "for depth of  6, the accuracy is 0.88\n",
      "for depth of  7, the accuracy is 0.89\n",
      "for depth of  8, the accuracy is 0.9\n",
      "for depth of  9, the accuracy is 0.91\n",
      "for depth of 10, the accuracy is 0.91\n",
      "for depth of 11, the accuracy is 0.9\n",
      "for depth of 12, the accuracy is 0.9\n",
      "for depth of 13, the accuracy is 0.91\n",
      "for depth of 14, the accuracy is 0.91\n",
      "for depth of 15, the accuracy is 0.91\n",
      "for depth of 16, the accuracy is 0.91\n",
      "for depth of 17, the accuracy is 0.91\n",
      "for depth of 18, the accuracy is 0.91\n",
      "for depth of 19, the accuracy is 0.91\n"
     ]
    }
   ],
   "source": [
    "# 4\n",
    "for x in range(1,20):\n",
    "        tree = rf(max_depth=x, random_state=4343,min_samples_leaf=4)\n",
    "        tree.fit(x_train, y_train)\n",
    "        acc = tree.score(x_train, y_train)\n",
    "        print(f'for depth of {x:2}, the accuracy is {round(acc,2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for depth of  1, the accuracy is 0.76\n",
      "for depth of  2, the accuracy is 0.78\n",
      "for depth of  3, the accuracy is 0.79\n",
      "for depth of  4, the accuracy is 0.79\n",
      "for depth of  5, the accuracy is 0.81\n",
      "for depth of  6, the accuracy is 0.81\n",
      "for depth of  7, the accuracy is 0.79\n",
      "for depth of  8, the accuracy is 0.82\n",
      "for depth of  9, the accuracy is 0.8\n",
      "for depth of 10, the accuracy is 0.8\n",
      "for depth of 11, the accuracy is 0.79\n",
      "for depth of 12, the accuracy is 0.79\n",
      "for depth of 13, the accuracy is 0.8\n",
      "for depth of 14, the accuracy is 0.8\n",
      "for depth of 15, the accuracy is 0.8\n",
      "for depth of 16, the accuracy is 0.8\n",
      "for depth of 17, the accuracy is 0.8\n",
      "for depth of 18, the accuracy is 0.8\n",
      "for depth of 19, the accuracy is 0.8\n"
     ]
    }
   ],
   "source": [
    "# 4 val\n",
    "for x in range(1,20):\n",
    "        tree = rf(max_depth=x, random_state=4343,min_samples_leaf=4)\n",
    "        tree.fit(x_train, y_train)\n",
    "        acc = tree.score(x_validate, y_validate)\n",
    "        print(f'for depth of {x:2}, the accuracy is {round(acc,2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for depth of  1, the accuracy is 0.8\n",
      "for depth of  2, the accuracy is 0.82\n",
      "for depth of  3, the accuracy is 0.84\n",
      "for depth of  4, the accuracy is 0.86\n",
      "for depth of  5, the accuracy is 0.87\n",
      "for depth of  6, the accuracy is 0.87\n",
      "for depth of  7, the accuracy is 0.89\n",
      "for depth of  8, the accuracy is 0.9\n",
      "for depth of  9, the accuracy is 0.89\n",
      "for depth of 10, the accuracy is 0.89\n",
      "for depth of 11, the accuracy is 0.9\n",
      "for depth of 12, the accuracy is 0.9\n",
      "for depth of 13, the accuracy is 0.9\n",
      "for depth of 14, the accuracy is 0.9\n",
      "for depth of 15, the accuracy is 0.89\n",
      "for depth of 16, the accuracy is 0.89\n",
      "for depth of 17, the accuracy is 0.89\n",
      "for depth of 18, the accuracy is 0.89\n",
      "for depth of 19, the accuracy is 0.89\n"
     ]
    }
   ],
   "source": [
    "# 5\n",
    "for x in range(1,20):\n",
    "        tree = rf(max_depth=x, random_state=4343,min_samples_leaf=5)\n",
    "        tree.fit(x_train, y_train)\n",
    "        acc = tree.score(x_train, y_train)\n",
    "        print(f'for depth of {x:2}, the accuracy is {round(acc,2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for depth of  1, the accuracy is 0.76\n",
      "for depth of  2, the accuracy is 0.78\n",
      "for depth of  3, the accuracy is 0.79\n",
      "for depth of  4, the accuracy is 0.79\n",
      "for depth of  5, the accuracy is 0.81\n",
      "for depth of  6, the accuracy is 0.8\n",
      "for depth of  7, the accuracy is 0.79\n",
      "for depth of  8, the accuracy is 0.81\n",
      "for depth of  9, the accuracy is 0.79\n",
      "for depth of 10, the accuracy is 0.79\n",
      "for depth of 11, the accuracy is 0.8\n",
      "for depth of 12, the accuracy is 0.79\n",
      "for depth of 13, the accuracy is 0.79\n",
      "for depth of 14, the accuracy is 0.8\n",
      "for depth of 15, the accuracy is 0.79\n",
      "for depth of 16, the accuracy is 0.79\n",
      "for depth of 17, the accuracy is 0.79\n",
      "for depth of 18, the accuracy is 0.79\n",
      "for depth of 19, the accuracy is 0.79\n"
     ]
    }
   ],
   "source": [
    "# 5 val\n",
    "for x in range(1,20):\n",
    "        tree = rf(max_depth=x, random_state=4343,min_samples_leaf=5)\n",
    "        tree.fit(x_train, y_train)\n",
    "        acc = tree.score(x_validate, y_validate)\n",
    "        print(f'for depth of {x:2}, the accuracy is {round(acc,2)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "codeup",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
